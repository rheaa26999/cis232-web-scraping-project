# -*- coding: utf-8 -*-
"""womens_volleyball

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PTBtdwwOJZlwcw-cFojy_QAoaGLYUqof
"""



import requests
from bs4 import BeautifulSoup
import pandas as pd
import csv
import re

# Convert heights like "5-9" or "5'9" to inches
def convert_height(h):
    if not h or h.strip() in ("-", ""):
        return None
    h = h.replace("’", "-").replace("'", "-").replace('"', "").strip()
    parts = h.split("-")
    if len(parts) != 2:
        return None
    try:
        return int(parts[0]) * 12 + int(parts[1])
    except:
        return None

# -------------- SCHOOL-SPECIFIC SCRAPERS --------------

# 1) BMCC — uses sidearm roster elements
def scrape_bmcc():
    url = "https://bmccathletics.com/sports/womens-volleyball/roster"
    res = requests.get(url)
    soup = BeautifulSoup(res.text, "html.parser")
    players = []
    for p in soup.select(".sidearm-roster-player"):
        name_tag = p.select_one(".sidearm-roster-player-name")
        ht_tag   = p.select_one(".sidearm-roster-player-height")
        if name_tag:
            name = name_tag.text.strip()
            height_raw = ht_tag.text.strip() if ht_tag else ""
            players.append(("BMCC", name, height_raw, convert_height(height_raw)))
    return players

# 2) York College — table-like rows with Name & Ht.
def scrape_york():
    url = "https://yorkathletics.com/sports/womens-volleyball/roster"
    res = requests.get(url)
    soup = BeautifulSoup(res.text, "html.parser")
    players = []
    for row in soup.select("table tbody tr"):
        cols = row.find_all("td")
        if len(cols) >= 5:
            name = cols[1].get_text(strip=True)
            height_raw = cols[4].get_text(strip=True)
            players.append(("York College", name, height_raw, convert_height(height_raw)))
    return players

# 3) Hostos CC — many rosters include height in text near players
def scrape_hostos():
    url = "https://hostosathletics.com/sports/womens-volleyball/roster"
    res = requests.get(url)
    soup = BeautifulSoup(res.text, "html.parser")
    players = []
    # Find rows by the pattern: "Full Name ... Height 5-?"
    for p in soup.select(".roster .player-name"):
        name = p.text.strip()
        # height often right after name
        txt = p.find_next_sibling(text=True)
        ht_match = re.search(r"(\d[-’']\d{1,2})", txt if txt else "")
        height_raw = ht_match.group(1) if ht_match else ""
        players.append(("Hostos CC", name, height_raw, convert_height(height_raw)))
    return players

# 4) Bronx CC — also uses sidearm roster-like elements
def scrape_bronx_cc():
    url = "https://bronxbroncos.com/sports/womens-volleyball/roster/2021"
    res = requests.get(url)
    soup = BeautifulSoup(res.text, "html.parser")
    players = []
    for p in soup.select(".sidearm-roster-player"):
        name_tag = p.select_one(".sidearm-roster-player-name")
        ht_tag   = p.select_one(".sidearm-roster-player-height")
        if name_tag:
            name = name_tag.text.strip()
            height_raw = ht_tag.text.strip() if ht_tag else ""
            players.append(("Bronx CC", name, height_raw, convert_height(height_raw)))
    return players

# 5) Queens College — similar table-like
def scrape_queens():
    url = "https://queensknights.com/sports/womens-volleyball/roster"
    res = requests.get(url)
    soup = BeautifulSoup(res.text, "html.parser")
    players = []
    for row in soup.select("table tbody tr"):
        cols = row.find_all("td")
        if len(cols) >= 5:
            name = cols[1].get_text(strip=True)
            height_raw = cols[4].get_text(strip=True)
            players.append(("Queens College", name, height_raw, convert_height(height_raw)))
    return players

# 6) Augusta College
def scrape_augusta():
    url = "https://augustajags.com/sports/wvball/roster"
    res = requests.get(url)
    soup = BeautifulSoup(res.text, "html.parser")
    players = []
    for row in soup.select("table tbody tr"):
        cols = row.find_all("td")
        if len(cols) >= 5:
            name = cols[1].get_text(strip=True)
            height_raw = cols[4].get_text(strip=True)
            players.append(("Augusta College", name, height_raw, convert_height(height_raw)))
    return players

# 7) Flagler College
def scrape_flagler():
    url = "https://flaglerathletics.com/sports/womens-volleyball/roster"
    res = requests.get(url)
    soup = BeautifulSoup(res.text, "html.parser")
    players = []
    for row in soup.select("table tbody tr"):
        cols = row.find_all("td")
        if len(cols) >= 5:
            name = cols[1].get_text(strip=True)
            height_raw = cols[4].get_text(strip=True)
            players.append(("Flagler College", name, height_raw, convert_height(height_raw)))
    return players

# 8) USC Aiken
def scrape_usc_aiken():
    url = "https://pacersports.com/sports/womens-volleyball/roster"
    res = requests.get(url)
    soup = BeautifulSoup(res.text, "html.parser")
    players = []
    for row in soup.select("table tbody tr"):
        cols = row.find_all("td")
        if len(cols) >= 5:
            name = cols[1].get_text(strip=True)
            height_raw = cols[4].get_text(strip=True)
            players.append(("USC Aiken", name, height_raw, convert_height(height_raw)))
    return players

# 9) Penn State - Lock Haven
def scrape_lock_haven():
    url = "https://www.golhu.com/sports/womens-volleyball/roster"
    res = requests.get(url)
    soup = BeautifulSoup(res.text, "html.parser")
    players = []
    for row in soup.select("table tbody tr"):
        cols = row.find_all("td")
        if len(cols) >= 5:
            name = cols[1].get_text(strip=True)
            height_raw = cols[4].get_text(strip=True)
            players.append(("Penn State - Lock Haven", name, height_raw, convert_height(height_raw)))
    return players


def main():
    scrapers = [
        scrape_bmcc,
        scrape_york,
        scrape_hostos,
        scrape_bronx_cc,
        scrape_queens,
        scrape_augusta,
        scrape_flagler,
        scrape_usc_aiken,
        scrape_lock_haven
    ]

    all_players = []
    for func in scrapers:
        try:
            print(f"Running {func.__name__}...")
            all_players += func()
        except Exception as e:
            print(f"Error in {func.__name__}: {e}")

    # Save to CSV
    df = pd.DataFrame(all_players, columns=["School","Name","Height Raw","Height (inches)"])
    df.to_csv("womens_volleyball.csv", index=False)
    print("\nCSV saved as womens_volleyball.csv")

    # Print table
    print("\nRoster Table:\n")
    print(df)

    # Average Height
    heights = df["Height (inches)"].dropna()
    if not heights.empty:
        avg = round(heights.mean(), 2)
        print(f"\nAverage height: {avg} inches")
    else:
        print("\nNo height data to calculate average.")

if __name__ == "__main__":
    main()